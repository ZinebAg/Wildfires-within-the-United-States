---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---
````{r, include=FALSE}

library(ggplot2)
library(tidyr)
library(dplyr)
library(corrplot)
library(maps)
library(tidyverse)
library(Hmisc)
library(zoo)
library(hrbrthemes) 
library(pscl)
library('plot.matrix')
library('psych')
library(bookdown)
library(quantreg)
library(latex2exp)
library(cowplot)
library(reshape2)
library(stargazer)
library(knitr)
library(stargazer)
library(caret)
library(Metrics)
library(hydroGOF)
````


### Land covers and meteorogical correlation


```{r, include = FALSE}
load ("../Data/data_train_DF.RData")
df <- data_train_DF
```


## Prediction of the number of fire depending of the land covers : 
 
Thanks to the previous results, the value of CNT will be predicted. First, let's check that the model that we construct fits the data. The principle of Cross validation will be used : take 70% of the dataset to train the model and the remaining 30% will be used to test the model.


```{r, echo = FALSE}

#Remove the NA values from the data

train<-df[!is.na(df$CNT),] 
train<-df[!is.na(df$BA),]
#Step 2 : Cross validation : 

set.seed(123)
#Creating training data as 70% of the dataset

random_sample <- createDataPartition (na.omit(train$CNT), p = 0.7, list = FALSE)
#Genrating training dataset form the random_sample

training <-train [random_sample,]
#Generating testing dataset from rows which are not in the training

testing <- train [-random_sample,]
#Step 3 : Build the model: 

model <- zeroinfl(CNT~ lc1+lc2+lc3+lc4+lc5+lc6+lc7+lc8+lc9+lc10+
                    lc11+lc12+lc13+lc14+lc15+lc16+lc17+lc18+
                    clim1+clim2+clim3+clim4+ clim5+ clim6+ clim7+clim8+clim9+
                    clim10+ altiMean+ altiSD, data = training)
save(model, file = "my_model1.rda")
#Prediction the test variable to check if our model is good
prediction <- predict(model, testing)

data.frame(R2 = R2(prediction, testing$CNT,na.rm = TRUE),
           RMSE = rmse(prediction, testing$CNT),
           MAE = mae(prediction, testing$CNT)) 
```


To measure the good fitting of our model, we compute the R squared, the mean squared error and the mean absolute error. Here the R squared is of order 0.15, this means that the model explains 15% of the variable CNT. The lower the rmse is, the better the model is able to fit a dataset. In this case the value is 6 but since our test set is of order 160 000 points, this means that the value is low for the test set. Finaly, the MAE is 2.48, on average the forecast's distance from the true value is 2.48.

To improve the model, we tried to use feature selection has been in r ( backward selection). It takes about 20 minutes to run, the code is available in the file ('predictCNTandBA.R'). It only delete clim4 as feature for the model. We are going to let the model as previously. And now, we predict the missing values in our dataframe and replace the NA values by the prediction.





```{r, echo = FALSE}
plot(prediction,testing$CNT, xlab = "Predicted Values", ylab = "Observed Values")
```




```{r, echo = FALSE}
load("../Code/my_model1.rda")
df<-data_train_DF
goal = df[is.na(df$CNT),]
goal$CNT = predict (model, goal)
data<-replace(df$CNT, is.na(df$CNT)== TRUE, goal$CNT)
df
is.na(df$CNT) == TRUE
```


### Prediction of BA : 


```{r, echo = FALSE}
sp = sample (nrow(training), 10000)
train = training[sp,]
train$BA = as.integer(train$BA)
select <- zeroinfl(BA~CNT+ lc1+lc2+lc3+lc4+lc5+lc6+lc7+lc8+lc9+lc10+
                   lc11+lc12+lc13+lc14+lc15+lc16+lc17+lc18+
                   clim1+clim2+clim3+clim4+ clim5+ clim6+ clim7+clim8+ clim9 +
                   clim10+ altiMean+ altiSD, data = train)
prediction <- predict(select, testing)
data.frame(R2 = R2(prediction, testing$BA,na.rm = TRUE),
           RMSE = rmse(prediction, testing$BA),
           MAE = mae(prediction, testing$BA)) 
```

Not good model, let's try another one 
```{r, echo = FALSE}
model2 <-glm (BA~ CNT+ lc1+lc2+lc3+lc4+lc5+lc6+lc7+lc8+lc9+lc10+
                   lc11+lc12+lc13+lc14+lc15+lc16+lc17+lc18+
                   clim1+clim2+clim3+clim4+ clim5+ clim6+ clim7+clim8+ clim9 +
                   clim10+ altiMean+ altiSD, data = training, family = 'gaussian')
prediction2 <-predict (model2, testing)
data.frame(R2 = R2(prediction2, testing$CNT,na.rm = TRUE),
           RMSE = rmse(prediction2, testing$BA),
           MAE = mae(prediction2, testing$BA))
```

Best model that we got. 
```{r, echo = FALSE}
goal = df[is.na(df$BA),]
goal$BA = predict (model2, goal)
data<-replace(df$CNT, is.na(df$CNT)== TRUE, goal$CNT)
df
is.na(df$CNT) == TRUE
```